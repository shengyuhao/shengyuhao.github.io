---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<head>
  <style>
  a { text-decoration : none; }
  a:hover { text-decoration : underline; }
  a, a:visited { color : #6e6f71; }
  p { font-size : 16px; }
  h3 { font-size : 18px; margin : 8; padding : 0; }
  h4 { font-size : 16px; margin : 6; padding : 0; }
  .container { width : 1000px;}
  .publogo { width: 100 px; margin-right : 20px; float : left; border : 10px;}
  .publication { clear : left; padding-bottom : 0px; }
  .publication p { height : 180px; padding-top : 0px;}
  .publication strong { font-size : 17px; color : #990036; }
  .publication strong a { font-size : 17px; color : #990036; }
  </style>
  </head>
  
  <div class="container">
  
  
  <h3>2024</h3>
  
  
  <div class="publication">
    <img src="../images/pubs/ego3dt.png" class="publogo" width="200 px" height="150 px">
    <p> 
      <strong>
        Ego3DT: Tracking Every 3D Object in Ego-centric Videos of Daily Activities
      </strong>
      <br>
      Shengyu Hao, Wenhao Chai, Zhonghan Zhao, Meiqi Sun, Wendi Hu, Jieyang Zhou, Yixian Zhao, Qi Li, Yizhou Wang, Xi Li, Gaoang Wang
      <br>
      <font color="#E89B00">
      <em>ACM Multimedia (MM), 2024</em>
      </font>
      <br>
      <a href="NA">[Paper]</a>
      <br>
      <font color="grey" size="2">
      We propose a novel zero-shot approach for the 3D reconstruction and tracking of all objects from the ego-centric video.
      </font>
    </p>
  </div>
  
  <h3>2023</h3>
    
  
  <div class="publication">
    <img src="../images/pubs/divotrack.png" class="publogo" width="200 px" height="160 px">
    <p> 
      <strong>
        DIVOTrack: A Novel Dataset and Baseline Method for Cross-View Multi-Object Tracking in DIVerse Open Scenes
      </strong>
      <br>
      Shengyu Hao, Peiyuan Liu, Yibing Zhan, Kaixun Jin, Zuozhu Liu, Mingli Song, Jenq-Neng Hwang, Gaoang Wang
      <br>
      <font color="#E89B00">
      <em>International Journal of Computer Vision (IJCV), 2023</em>
      </font>
      <br>
      <a href="https://arxiv.org/abs/2302.07676">[Paper]</a>
      <a href="https://huggingface.co/datasets/syhao777/DIVOTrack">[Dataset]</a>
      <a href="https://github.com/shengyuhao/DIVOTrack">[Code]</a>
      <img alt="" src="https://img.shields.io/github/stars/shengyuhao/DIVOTrack?style=social">
      <br>
      <font color="grey" size="2">
        A new cross-view multi-object tracking dataset for DIVerse Open scenes with dense tracking pedestrians.
      </font>
    </p>
  </div>
  
  <div class="publication">
    <img src="../images/pubs/diffashion.png" class="publogo" width="200 px" height="150 px">
    <p> 
      <strong>
        DiffFashion: Reference-based Fashion Design with Structure-aware Transfer by Diffusion Models
      </strong>
      <br>
      Shidong Cao, Wenhao Chai, Shengyu Hao, Yanting Zhang, Hangyue Chen, Gaoang Wang
      <br>
      <font color="#E89B00">
      <em>IEEE Transactions on Multimedia (TMM), 2023</em>
      </font>
      <br>
      <a href="https://arxiv.org/abs/2302.06826">[Paper]</a>
      <a href="https://github.com/Rem105-210/DiffFashion">[Code]</a>
      <img alt="" src="https://img.shields.io/github/stars/Rem105-210/DiffFashion?style=social">
      <br>
      <font color="grey" size="2">
        We transfer a reference appearance image onto a clothing image while preserving the structure of the clothing image. 
      </font>
    </p>
  </div>
  
  <h3>2021</h3>
  
  <div class="publication">
      <img src="../images/pubs/wsis.png" class="publogo" width="200 px" height="160 px">
      <p> 
        <strong>
          Weakly supervised instance segmentation using multi-prior fusion
        </strong>
        <br>
        Shengyu Hao, Gaoang Wang, Renshu Gu
        <br>
        <font color="#E89B00">
        <em>Computer Vision and Image Understanding (CVIU), 2021</em>
        </font>
        <br>
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S1077314221001053">[Paper]</a>
        <br>
        <font color="grey" size="2">
          We propose a novel method that combines multiple priors for mask generation.
        </font>
      </p>
  </div>
  
  
  </div>